# -*- coding: utf-8 -*-
"""credit card customer segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQ-mZQO0mX--orO-69d0QL8DG3_AS0Eo
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df= pd.read_csv('/content/BankChurners.csv')

df.head()

df.info()

df.describe()

df = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',
        'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1)

df.head()

df['Attrition_Flag'].unique()

sns.heatmap(df.corr())

sns.pairplot(df)

df.dtypes

df['Income_Category'].unique()

df['Marital_Status'].unique()

df['Card_Category'].unique()

df['Education_Level'].unique()

df.isnull().sum()

df[df == 'Unknown'].count()

df[df == 0].count()

df['Attrition_Flag'] = df.Attrition_Flag.map({'Attrited Customer': 1,
                                               'Existing Customer': 0})

df['Gender'] = df.Gender.map({'M': 1,'F': 0})

df['Education_Level'] = df.Education_Level.map({'Uneducated': 0, 'High School': 1,'Graduate': 2, 'College':3, 'Post-Graduate':4, 'Doctorate':5, 'Unknown':6})

df['Marital_Status'] = df.Marital_Status.map({'Unknown': 0, 'Single': 1,'Married': 2, 'Divorced': 3})

df.head()

df['Card_Category'] = df.Card_Category.map({'Blue': 0, 'Gold': 1,'Silver': 2, 'Platinum': 3})

df.head()

df['Income_Category'] =  df['Income_Category'].map({'Unknown':1,
                                                'Less than $40K':1,
                                                '$40K - $60K':2,
                                                '$60K - $80K':3,
                                                '$80K - $120K':4,
                                                '$120K +':5})

df.head()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder



# numericals = ['Dependent_count',
#             'Total_Relationship_Count',
#             'Months_Inactive_12_mon',
#             'Contacts_Count_12_mon',
#             'Total_Trans_Ct',
#             'Avg_Utilization_Ratio',
#              'Income_Category']

# X = df[numericals]

# scaler = StandardScaler()
# scaler.fit(X)

from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.metrics import roc_curve
from sklearn.metrics import auc
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix

from sklearn.model_selection import cross_val_score, KFold

X= df.drop('Attrition_Flag', axis=1)
y= df['Attrition_Flag']

y.shape

print(X.shape)

X.head()

X.isnull().sum()

y.unique()

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)

gnb = GaussianNB()
gnb.fit(X_train, y_train)

y_pred= gnb.predict(X_test)

confusion_matrix(y_test, y_pred)

accuracy_score(y_test, y_pred)

lr= LogisticRegression()
lr.fit(X_train, y_train)

y_pred2= lr.predict(X_test)

accuracy_score(y_test, y_pred2)

confusion_matrix(y_test, y_pred2)

knn = KNeighborsClassifier(n_neighbors=200)

knn.fit(X_train, y_train)

y_pred3= knn.predict(X_test)

accuracy_score(y_test, y_pred3)

confusion_matrix(y_test, y_pred3)

